{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```thinking\n",
      "让我从软件架构师和AI专家的角度来思考这个问题...\n",
      "\n",
      "首先这是一个典型的命名实体识别(NER)任务,需要从非结构化文本中识别出地理位置实体。对于中文文本处理会有一些特殊的考虑...\n",
      "\n",
      "hmm,从技术选型上来看,有几个可能的方案:\n",
      "\n",
      "1. 最简单的是使用现成的中文NLP库,像是go-nlp或者调用一些云服务API。但这种方式可能不够灵活,而且依赖第三方。\n",
      "\n",
      "2. 另一个方向是自己实现基于规则的方法,使用地名词典匹配。这种方式实现简单,但准确率可能不够高,而且需要维护词典。\n",
      "\n",
      "3. 更好的方案是使用机器学习模型,特别是预训练的中文语言模型。但golang在深度学习方面的生态还不够成熟...\n",
      "\n",
      "让我想想具体的实现细节...\n",
      "\n",
      "对于数据预处理,肯定需要先进行分词。这里可以用jieba分词的golang实现。\n",
      "\n",
      "然后是实体识别的核心部分。考虑到实际应用场景,我觉得可以采用混合方案:\n",
      "- 基础层使用预定义的地名词典快速匹配\n",
      "- 结合一些启发式规则,比如\"省\"、\"市\"等关键词\n",
      "- 可选地调用预训练模型做进一步识别\n",
      "\n",
      "还需要考虑地名的层级关系。比如\"北京市海淀区\"这样的嵌套地名,需要正确解析出层级。可以构建一个树形结构来表示。\n",
      "\n",
      "具体到golang库的选择:\n",
      "- 分词可以用github.com/yanyiwu/gojieba\n",
      "- 正则表达式标准库regexp\n",
      "- 可以用gorm操作地名数据库\n",
      "- 如果要用深度学习,可以考虑调用Python服务\n",
      "\n",
      "性能方面需要注意的点:\n",
      "- 大规模词典匹配要用高效的数据结构,比如Trie树\n",
      "- 考虑使用goroutine并行处理\n",
      "- 结果缓存机制\n",
      "\n",
      "代码架构上应该遵循Clean Architecture:\n",
      "- 领域层定义地理实体模型\n",
      "- 应用层处理业务逻辑\n",
      "- 基础设施层处理具体的NLP操作\n",
      "\n",
      "嗯,这样的方案应该是比较完整和可行的。让我整理一下回复...\n",
      "```\n",
      "\n",
      "基于以上分析,我建议采用以下方案来实现中文地名提取:\n",
      "\n",
      "1. 核心依赖库:\n",
      "- github.com/yanyiwu/gojieba - 中文分词\n",
      "- github.com/go-gorm/gorm - 数据库操作\n",
      "- 标准库 regexp - 正则匹配\n",
      "\n",
      "2. 主要技术方案:\n",
      "- 采用分层的混合识别策略:\n",
      "  * 基于词典的快速匹配\n",
      "  * 规则识别(关键词、正则表达式)\n",
      "  * 可选的机器学习模型调用\n",
      "\n",
      "3. 基本实现步骤:\n",
      "\n",
      "```go\n",
      "type Location struct {\n",
      "    Name     string\n",
      "    Type     string  // country/province/city\n",
      "    Parent   *Location\n",
      "    Children []*Location\n",
      "}\n",
      "\n",
      "func ExtractLocations(text string) ([]*Location, error) {\n",
      "    // 1. 分词\n",
      "    words := jieba.Cut(text, true)\n",
      "    \n",
      "    // 2. 词典匹配\n",
      "    locations := matchDictionary(words)\n",
      "    \n",
      "    // 3. 规则识别\n",
      "    locations = append(locations, matchRules(text)...)\n",
      "    \n",
      "    // 4. 构建层级关系\n",
      "    return buildHierarchy(locations), nil\n",
      "}\n",
      "```\n",
      "\n",
      "4. 性能优化建议:\n",
      "- 使用 Trie 树进行词典匹配\n",
      "- 利用 goroutine 并行处理长文本\n",
      "- 实现结果缓存机制\n",
      "\n",
      "5. NLP 相关技术:\n",
      "- 命名实体识别(NER)\n",
      "- 中文分词\n",
      "- 规则匹配\n",
      "- 可选的深度学习模型\n",
      "\n",
      "这个方案可以根据实际需求进行扩展和调整。如果需要更高的准确率,可以考虑:\n",
      "1. 接入第三方 NLP 服务\n",
      "2. 使用预训练的中文语言模型\n",
      "3. 构建自己的训练数据集进行模型训练"
     ]
    }
   ],
   "source": [
    "import my_ast\n",
    "my_ast.process_prompt('./prompt-base.md', \"\"\"\n",
    "You play the role of a software architect, AI expert, and telecommunications expert to answer questions for me.\n",
    "如何使用golang从一个句子中提取出所有的地名，区分国家城市和省份\n",
    "会使用到哪些库和NLP技术\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我是 Claude，一个由 Anthropic 开发的 AI 助手。我会努力用专业、诚实和有帮助的方式来回答你的问题。"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "api_key=os.getenv(\"ONEAPI_API_KEY\", \"\")\n",
    "base_url=os.getenv(\"ONEAPI_BASE_URL\", \"\")\n",
    "\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(api_key=api_key, base_url=base_url, model=\"claude-3-5-sonnet\")\n",
    "response = llm.stream(\"你是哪个版本的模型\")\n",
    "for chunk in response:\n",
    "    print(chunk.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "prompt = open('prompt-base.md', 'r', encoding='utf-8').read()\n",
    "prompt = prompt + \"\"\"\n",
    "把下面的代码进行函数和类抽取重构，使之更简洁，易扩展，易维护，代码不需要注释\n",
    "新代码应该支持修改模型名称，是否使用流式\n",
    "```python\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "import datetime\n",
    "\n",
    "load_dotenv(find_dotenv(),override=True)\n",
    "api_key=os.getenv(\"ONEAPI_API_KEY\", \"\")\n",
    "base_url=os.getenv(\"ONEAPI_BASE_URL\", \"\")\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(api_key=api_key, base_url=base_url, model=\"claude-3-5-sonnet\")\n",
    "\n",
    "prompt = open('prompt-base.md', 'r', encoding='utf-8').read()\n",
    "prompt = prompt + \"1.8 和 1.11 谁大\"\n",
    "response = llm.stream(prompt)\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "file_path = f'sessions/temp-{timestamp}.md'\n",
    "\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    for chunk in response:\n",
    "        print(chunk.content, end=\"\")\n",
    "        file.write(chunk.content)\n",
    "```\n",
    "\"\"\"\n",
    "response = llm.stream(prompt)\n",
    "# 获取当前时间戳\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "# 定义文件路径\n",
    "file_path = f'sessions/temp-{timestamp}.md'\n",
    "\n",
    "# 将内容写入文件\n",
    "with open(file_path, 'w', encoding='utf-8') as file:\n",
    "    for chunk in response:\n",
    "        # print(chunk.content, end=\"\")\n",
    "        file.write(chunk.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
