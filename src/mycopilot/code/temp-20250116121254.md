**设计思路**

我们的目标是创建一个 Python 程序，它可以加载代码，对代码进行压缩描述，并将这些信息合并成一个用于大型模型的提示（prompt）。为了实现这一点，我们将采用模块化的设计，每个模块负责特定的任务。

1. **配置管理 (Configuration):** 使用 `pydantic` 来管理配置，例如代码目录或文件路径。
2. **代码加载 (Code Loading):** 负责从指定的目录或文件中读取源代码。
3. **代码压缩 (Code Compression):** 使用大型模型（这里我们模拟一个）来分析代码并生成代码的概要描述，包括函数概要和调用关系。
4. **提示生成 (Prompt Generation):** 将原始代码或压缩后的描述合并成一个完整的提示字符串。
5. **主程序 (Main Application):** 协调各个模块的操作。

**设计模式**

* **Strategy 模式 (Strategy Pattern):** 在代码压缩模块中，我们可以使用策略模式来支持不同的代码压缩策略。例如，一个策略是直接返回原始代码，另一个策略是调用大型模型进行分析。这样可以方便地扩展和切换不同的压缩方式。

**文件结构**

```
ai_code_prompt/
├── config.py         # 配置文件
├── code_loader.py    # 代码加载模块
├── code_compressor.py # 代码压缩模块
├── prompt_generator.py # 提示生成模块
├── main.py           # 主程序入口
├── models.py         # Pydantic 数据模型
└── utils.py          # 通用工具函数
```

**代码描述**

**1. `config.py`**

*   定义使用 `pydantic` 的配置类，用于存储代码路径等配置信息。

**2. `models.py`**

*   定义 `pydantic` 模型，用于表示代码文件内容和压缩后的描述。

**3. `utils.py`**

*   包含一些通用的工具函数，例如文件读取等。

**4. `code_loader.py`**

*   `load_file_content(filepath: str) -> str`: 读取单个文件的内容。
*   `load_directory_content(dirpath: str) -> Dict[str, str]`: 遍历目录，读取所有代码文件的内容，返回一个文件名到内容的字典。
*   `load_code(path: str) -> Dict[str, str]`: 根据提供的路径是文件还是目录，调用相应的加载函数。

**5. `code_compressor.py`**

*   定义一个抽象的 `CodeCompressionStrategy` 基类或接口，包含一个 `compress` 方法。
*   实现具体的压缩策略，例如 `OriginalCodeStrategy`（直接返回原始代码）和 `LLMCompressionStrategy`（模拟使用大型模型进行代码分析）。
*   `compress_code(code_snippets: Dict[str, str], strategy: CodeCompressionStrategy) -> Dict[str, str]`: 使用指定的策略压缩代码片段。

**6. `prompt_generator.py`**

*   `merge_code_descriptions(descriptions: Dict[str, str]) -> str`: 将多个文件的描述合并成一个字符串。
*   `merge_code(code_snippets: Dict[str, str]) -> str`: 将多个文件的原始代码合并成一个字符串。
*   `create_prompt(main_content: str, prefix: str = "", suffix: str = "") -> str`: 创建最终的提示，可以添加前缀和后缀。

**7. `main.py`**

*   主程序入口，负责解析配置，调用代码加载、压缩和提示生成模块。

**使用方法**

1. 将以上代码保存到相应的 `.py` 文件中。
2. 根据需要修改 `config.py` 中的 `code_path` 来指定要加载的代码文件或目录。
3. 运行 `main.py` 文件。

**示例运行**

假设你的当前目录下有一些 Python 代码文件，运行 `main.py` 后，你将会看到生成的 Prompt。如果 `compression_strategy` 设置为 "llm"，则会模拟大型模型的分析过程。

**进一步改进**

*   **真正的 LLM 集成:** 将 `LLMCompressionStrategy` 修改为真正调用大型模型的 API，例如 OpenAI 的 API。
*   **更灵活的文件类型支持:** 在 `utils.py` 中扩展支持的代码文件类型。
*   **更精细的配置:** 允许配置更详细的 Prompt 前缀和后缀。
*   **错误处理:** 添加更完善的错误处理机制。
*   **单元测试:** 为每个模块编写单元测试，确保代码的质量和稳定性。

希望这个设计方案能够帮助你构建你的 AI 程序！
